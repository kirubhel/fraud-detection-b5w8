{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B5W8: Fraud Detection - Model Building and Evaluation\n",
    "\n",
    "**Interim 2 Submission**\n",
    "\n",
    "This notebook focuses on:\n",
    "1. Model building and training\n",
    "2. Handling class imbalance\n",
    "3. Model evaluation with appropriate metrics\n",
    "4. SHAP explainability implementation\n",
    "\n",
    "**Author:** Kirubel Gizaw  \n",
    "**Challenge:** B5W8 â€” Tenx Platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m      6\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    precision_recall_curve, average_precision_score, f1_score\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = pd.read_csv('../data/Fraud_Data.csv')\n",
    "ip_country_data = pd.read_csv('../data/IpAddress_to_Country.csv')\n",
    "credit_data = pd.read_csv('../data/creditcard.csv')\n",
    "\n",
    "print(f\"Fraud Data shape: {fraud_data.shape}\")\n",
    "print(f\"IP Country Data shape: {ip_country_data.shape}\")\n",
    "print(f\"Credit Card Data shape: {credit_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
    "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
    "\n",
    "fraud_data['time_since_signup'] = (fraud_data['purchase_time'] - fraud_data['signup_time']).dt.total_seconds()\n",
    "fraud_data['hour_of_day'] = fraud_data['purchase_time'].dt.hour\n",
    "fraud_data['day_of_week'] = fraud_data['purchase_time'].dt.dayofweek\n",
    "\n",
    "def ip_to_int(ip):\n",
    "    parts = ip.split('.')\n",
    "    return int(parts[0]) * 256**3 + int(parts[1]) * 256**2 + int(parts[2]) * 256 + int(parts[3])\n",
    "\n",
    "fraud_data['ip_int'] = fraud_data['ip_address'].apply(ip_to_int)\n",
    "\n",
    "def find_country(ip_int, ip_ranges):\n",
    "    for _, row in ip_ranges.iterrows():\n",
    "        if row['lower_bound_ip_address'] <= ip_int <= row['upper_bound_ip_address']:\n",
    "            return row['country']\n",
    "    return 'Unknown'\n",
    "\n",
    "fraud_data['country'] = fraud_data['ip_int'].apply(lambda x: find_country(x, ip_country_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features\n",
    "ecommerce_features = [\n",
    "    'purchase_value', 'time_since_signup', 'hour_of_day', 'day_of_week',\n",
    "    'age', 'source', 'browser', 'sex', 'country'\n",
    "]\n",
    "\n",
    "# Encode categorical variables\n",
    "le_source = LabelEncoder()\n",
    "le_browser = LabelEncoder()\n",
    "le_sex = LabelEncoder()\n",
    "le_country = LabelEncoder()\n",
    "\n",
    "fraud_data['source_encoded'] = le_source.fit_transform(fraud_data['source'])\n",
    "fraud_data['browser_encoded'] = le_browser.fit_transform(fraud_data['browser'])\n",
    "fraud_data['sex_encoded'] = le_sex.fit_transform(fraud_data['sex'])\n",
    "fraud_data['country_encoded'] = le_country.fit_transform(fraud_data['country'])\n",
    "\n",
    "# Final feature list\n",
    "ecommerce_final_features = [\n",
    "    'purchase_value', 'time_since_signup', 'hour_of_day', 'day_of_week',\n",
    "    'age', 'source_encoded', 'browser_encoded', 'sex_encoded', 'country_encoded'\n",
    "]\n",
    "\n",
    "X_ecommerce = fraud_data[ecommerce_final_features]\n",
    "y_ecommerce = fraud_data['class']\n",
    "\n",
    "print(f\"E-commerce features shape: {X_ecommerce.shape}\")\n",
    "print(f\"E-commerce target distribution:\\n{y_ecommerce.value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns\n",
    "credit_features = [col for col in credit_data.columns if col not in ['Time', 'Class']]\n",
    "\n",
    "X_credit = credit_data[credit_features]\n",
    "y_credit = credit_data['Class']\n",
    "\n",
    "print(f\"Credit card features shape: {X_credit.shape}\")\n",
    "print(f\"Credit card target distribution:\\n{y_credit.value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SMOTE and RandomUnderSampler\n",
    "smote = SMOTE(random_state=42)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "print(\"Sampling techniques initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "print(\"Models initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, y_prob, model_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation function for imbalanced classification\n",
    "    \"\"\"\n",
    "    auc_roc = roc_auc_score(y_true, y_prob)\n",
    "    auc_pr = average_precision_score(y_true, y_prob)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'dataset': dataset_name,\n",
    "        'auc_roc': auc_roc,\n",
    "        'auc_pr': auc_pr,\n",
    "        'f1_score': f1,\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "print(\"Evaluation function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and scale\n",
    "X_train_ecom, X_test_ecom, y_train_ecom, y_test_ecom = train_test_split(\n",
    "    X_ecommerce, y_ecommerce, test_size=0.2, random_state=42, stratify=y_ecommerce\n",
    ")\n",
    "\n",
    "scaler_ecom = StandardScaler()\n",
    "X_train_ecom_scaled = scaler_ecom.fit_transform(X_train_ecom)\n",
    "X_test_ecom_scaled = scaler_ecom.transform(X_test_ecom)\n",
    "\n",
    "# Apply SMOTE\n",
    "X_train_ecom_balanced, y_train_ecom_balanced = smote.fit_resample(X_train_ecom_scaled, y_train_ecom)\n",
    "\n",
    "# Train and evaluate\n",
    "ecommerce_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} on e-commerce data...\")\n",
    "    model.fit(X_train_ecom_balanced, y_train_ecom_balanced)\n",
    "    y_pred = model.predict(X_test_ecom_scaled)\n",
    "    y_prob = model.predict_proba(X_test_ecom_scaled)[:, 1]\n",
    "    results = evaluate_model(y_test_ecom, y_pred, y_prob, name, 'E-commerce')\n",
    "    ecommerce_results.append(results)\n",
    "    print(f\"{name} - AUC-ROC: {results['auc_roc']:.4f}, F1: {results['f1_score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and scale\n",
    "X_train_credit, X_test_credit, y_train_credit, y_test_credit = train_test_split(\n",
    "    X_credit, y_credit, test_size=0.2, random_state=42, stratify=y_credit\n",
    ")\n",
    "\n",
    "scaler_credit = StandardScaler()\n",
    "X_train_credit_scaled = scaler_credit.fit_transform(X_train_credit)\n",
    "X_test_credit_scaled = scaler_credit.transform(X_test_credit)\n",
    "\n",
    "# Apply SMOTE\n",
    "X_train_credit_balanced, y_train_credit_balanced = smote.fit_resample(X_train_credit_scaled, y_train_credit)\n",
    "\n",
    "# Train and evaluate\n",
    "credit_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} on credit card data...\")\n",
    "    model.fit(X_train_credit_balanced, y_train_credit_balanced)\n",
    "    y_pred = model.predict(X_test_credit_scaled)\n",
    "    y_prob = model.predict_proba(X_test_credit_scaled)[:, 1]\n",
    "    results = evaluate_model(y_test_credit, y_pred, y_prob, name, 'Credit Card')\n",
    "    credit_results.append(results)\n",
    "    print(f\"{name} - AUC-ROC: {results['auc_roc']:.4f}, F1: {results['f1_score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(ecommerce_results + credit_results)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# AUC-ROC\n",
    "for dataset in ['E-commerce', 'Credit Card']:\n",
    "    data = results_df[results_df['dataset'] == dataset]\n",
    "    axes[0, 0].bar(data['model'], data['auc_roc'], label=dataset, alpha=0.7)\n",
    "axes[0, 0].set_title('AUC-ROC Score Comparison')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# F1 Score\n",
    "for dataset in ['E-commerce', 'Credit Card']:\n",
    "    data = results_df[results_df['dataset'] == dataset]\n",
    "    axes[0, 1].bar(data['model'], data['f1_score'], label=dataset, alpha=0.7)\n",
    "axes[0, 1].set_title('F1 Score Comparison')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Precision vs Recall\n",
    "for dataset in ['E-commerce', 'Credit Card']:\n",
    "    data = results_df[results_df['dataset'] == dataset]\n",
    "    axes[1, 0].scatter(data['precision'], data['recall'], s=100, alpha=0.7, label=dataset)\n",
    "axes[1, 0].set_title('Precision vs Recall')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# AUC-PR\n",
    "for dataset in ['E-commerce', 'Credit Card']:\n",
    "    data = results_df[results_df['dataset'] == dataset]\n",
    "    axes[1, 1].bar(data['model'], data['auc_pr'], label=dataset, alpha=0.7)\n",
    "axes[1, 1].set_title('AUC-PR Score Comparison')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
