{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B5W8: Fraud Detection - Model Building and Evaluation\n",
    "\n",
    "**Interim 2 Submission**\n",
    "\n",
    "This notebook focuses on:\n",
    "1. Model building and training\n",
    "2. Handling class imbalance\n",
    "3. Model evaluation with appropriate metrics\n",
    "4. SHAP explainability implementation\n",
    "\n",
    "**Author:** Kirubel Gizaw  \n",
    "**Challenge:** B5W8 â€” Tenx Platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    precision_recall_curve, average_precision_score, f1_score\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Data shape: (151112, 11)\n",
      "IP Country Data shape: (138846, 3)\n",
      "Credit Card Data shape: (284807, 31)\n"
     ]
    }
   ],
   "source": [
    "fraud_data = pd.read_csv('../data/Fraud_Data.csv')\n",
    "ip_country_data = pd.read_csv('../data/IpAddress_to_Country.csv')\n",
    "credit_data = pd.read_csv('../data/creditcard.csv')\n",
    "\n",
    "print(f\"Fraud Data shape: {fraud_data.shape}\")\n",
    "print(f\"IP Country Data shape: {ip_country_data.shape}\")\n",
    "print(f\"Credit Card Data shape: {credit_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
    "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
    "\n",
    "fraud_data['time_since_signup'] = (fraud_data['purchase_time'] - fraud_data['signup_time']).dt.total_seconds()\n",
    "fraud_data['hour_of_day'] = fraud_data['purchase_time'].dt.hour\n",
    "fraud_data['day_of_week'] = fraud_data['purchase_time'].dt.dayofweek\n",
    "\n",
    "def ip_to_int(ip):\n",
    "    if isinstance(ip, str) and ip.count('.') == 3:\n",
    "        parts = ip.split('.')\n",
    "        try:\n",
    "            return int(parts[0]) * 256**3 + int(parts[1]) * 256**2 + int(parts[2]) * 256 + int(parts[3])\n",
    "        except ValueError:\n",
    "            return -1  # handle non-integer parts gracefully\n",
    "    return -1  # fallback for NaN or malformed IPs\n",
    "\n",
    "fraud_data['ip_int'] = fraud_data['ip_address'].apply(ip_to_int)\n",
    "\n",
    "\n",
    "def find_country(ip_int, ip_ranges):\n",
    "    for _, row in ip_ranges.iterrows():\n",
    "        if row['lower_bound_ip_address'] <= ip_int <= row['upper_bound_ip_address']:\n",
    "            return row['country']\n",
    "    return 'Unknown'\n",
    "\n",
    "fraud_data['country'] = fraud_data['ip_int'].apply(lambda x: find_country(x, ip_country_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features\n",
    "ecommerce_features = [\n",
    "    'purchase_value', 'time_since_signup', 'hour_of_day', 'day_of_week',\n",
    "    'age', 'source', 'browser', 'sex', 'country'\n",
    "]\n",
    "\n",
    "# Encode categorical variables\n",
    "le_source = LabelEncoder()\n",
    "le_browser = LabelEncoder()\n",
    "le_sex = LabelEncoder()\n",
    "le_country = LabelEncoder()\n",
    "\n",
    "fraud_data['source_encoded'] = le_source.fit_transform(fraud_data['source'])\n",
    "fraud_data['browser_encoded'] = le_browser.fit_transform(fraud_data['browser'])\n",
    "fraud_data['sex_encoded'] = le_sex.fit_transform(fraud_data['sex'])\n",
    "fraud_data['country_encoded'] = le_country.fit_transform(fraud_data['country'])\n",
    "\n",
    "# Final feature list\n",
    "ecommerce_final_features = [\n",
    "    'purchase_value', 'time_since_signup', 'hour_of_day', 'day_of_week',\n",
    "    'age', 'source_encoded', 'browser_encoded', 'sex_encoded', 'country_encoded'\n",
    "]\n",
    "\n",
    "X_ecommerce = fraud_data[ecommerce_final_features]\n",
    "y_ecommerce = fraud_data['class']\n",
    "\n",
    "print(f\"E-commerce features shape: {X_ecommerce.shape}\")\n",
    "print(f\"E-commerce target distribution:\\n{y_ecommerce.value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns\n",
    "credit_features = [col for col in credit_data.columns if col not in ['Time', 'Class']]\n",
    "\n",
    "X_credit = credit_data[credit_features]\n",
    "y_credit = credit_data['Class']\n",
    "\n",
    "print(f\"Credit card features shape: {X_credit.shape}\")\n",
    "print(f\"Credit card target distribution:\\n{y_credit.value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SMOTE and RandomUnderSampler\n",
    "smote = SMOTE(random_state=42)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "print(\"Sampling techniques initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "print(\"Models initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, y_prob, model_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation function for imbalanced classification\n",
    "    \"\"\"\n",
    "    auc_roc = roc_auc_score(y_true, y_prob)\n",
    "    auc_pr = average_precision_score(y_true, y_prob)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'dataset': dataset_name,\n",
    "        'auc_roc': auc_roc,\n",
    "        'auc_pr': auc_pr,\n",
    "        'f1_score': f1,\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "print(\"Evaluation function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and scale\n",
    "X_train_ecom, X_test_ecom, y_train_ecom, y_test_ecom = train_test_split(\n",
    "    X_ecommerce, y_ecommerce, test_size=0.2, random_state=42, stratify=y_ecommerce\n",
    ")\n",
    "\n",
    "scaler_ecom = StandardScaler()\n",
    "X_train_ecom_scaled = scaler_ecom.fit_transform(X_train_ecom)\n",
    "X_test_ecom_scaled = scaler_ecom.transform(X_test_ecom)\n",
    "\n",
    "# Apply SMOTE\n",
    "X_train_ecom_balanced, y_train_ecom_balanced = smote.fit_resample(X_train_ecom_scaled, y_train_ecom)\n",
    "\n",
    "# Train and evaluate\n",
    "ecommerce_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} on e-commerce data...\")\n",
    "    model.fit(X_train_ecom_balanced, y_train_ecom_balanced)\n",
    "    y_pred = model.predict(X_test_ecom_scaled)\n",
    "    y_prob = model.predict_proba(X_test_ecom_scaled)[:, 1]\n",
    "    results = evaluate_model(y_test_ecom, y_pred, y_prob, name, 'E-commerce')\n",
    "    ecommerce_results.append(results)\n",
    "    print(f\"{name} - AUC-ROC: {results['auc_roc']:.4f}, F1: {results['f1_score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and scale\n",
    "X_train_credit, X_test_credit, y_train_credit, y_test_credit = train_test_split(\n",
    "    X_credit, y_credit, test_size=0.2, random_state=42, stratify=y_credit\n",
    ")\n",
    "\n",
    "scaler_credit = StandardScaler()\n",
    "X_train_credit_scaled = scaler_credit.fit_transform(X_train_credit)\n",
    "X_test_credit_scaled = scaler_credit.transform(X_test_credit)\n",
    "\n",
    "# Apply SMOTE\n",
    "X_train_credit_balanced, y_train_credit_balanced = smote.fit_resample(X_train_credit_scaled, y_train_credit)\n",
    "\n",
    "# Train and evaluate\n",
    "credit_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} on credit card data...\")\n",
    "    model.fit(X_train_credit_balanced, y_train_credit_balanced)\n",
    "    y_pred = model.predict(X_test_credit_scaled)\n",
    "    y_prob = model.predict_proba(X_test_credit_scaled)[:, 1]\n",
    "    results = evaluate_model(y_test_credit, y_pred, y_prob, name, 'Credit Card')\n",
    "    credit_results.append(results)\n",
    "    print(f\"{name} - AUC-ROC: {results['auc_roc']:.4f}, F1: {results['f1_score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(ecommerce_results + credit_results)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# AUC-ROC\n",
    "for dataset in ['E-commerce', 'Credit Card']:\n",
    "    data = results_df[results_df['dataset'] == dataset]\n",
    "    axes[0, 0].bar(data['model'], data['auc_roc'], label=dataset, alpha=0.7)\n",
    "axes[0, 0].set_title('AUC-ROC Score Comparison')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# F1 Score\n",
    "for dataset in ['E-commerce', 'Credit Card']:\n",
    "    data = results_df[results_df['dataset'] == dataset]\n",
    "    axes[0, 1].bar(data['model'], data['f1_score'], label=dataset, alpha=0.7)\n",
    "axes[0, 1].set_title('F1 Score Comparison')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Precision vs Recall\n",
    "for dataset in ['E-commerce', 'Credit Card']:\n",
    "    data = results_df[results_df['dataset'] == dataset]\n",
    "    axes[1, 0].scatter(data['precision'], data['recall'], s=100, alpha=0.7, label=dataset)\n",
    "axes[1, 0].set_title('Precision vs Recall')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# AUC-PR\n",
    "for dataset in ['E-commerce', 'Credit Card']:\n",
    "    data = results_df[results_df['dataset'] == dataset]\n",
    "    axes[1, 1].bar(data['model'], data['auc_pr'], label=dataset, alpha=0.7)\n",
    "axes[1, 1].set_title('AUC-PR Score Comparison')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ecom_model_name = results_df[results_df['dataset'] == 'E-commerce']['model'].iloc[\n",
    "    results_df[results_df['dataset'] == 'E-commerce']['f1_score'].idxmax()\n",
    "]\n",
    "\n",
    "best_credit_model_name = results_df[results_df['dataset'] == 'Credit Card']['model'].iloc[\n",
    "    results_df[results_df['dataset'] == 'Credit Card']['f1_score'].idxmax()\n",
    "]\n",
    "\n",
    "print(f\"Best E-commerce model: {best_ecom_model_name}\")\n",
    "print(f\"Best Credit Card model: {best_credit_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== SHAP Analysis for E-commerce Data ===\")\n",
    "\n",
    "best_ecom_model = models[best_ecom_model_name]\n",
    "best_ecom_model.fit(X_train_ecom_balanced, y_train_ecom_balanced)\n",
    "\n",
    "if hasattr(best_ecom_model, 'feature_importances_'):\n",
    "    explainer = shap.TreeExplainer(best_ecom_model)\n",
    "    shap_values = explainer.shap_values(X_test_ecom_scaled[:100])\n",
    "else:\n",
    "    explainer = shap.LinearExplainer(best_ecom_model, X_train_ecom_balanced)\n",
    "    shap_values = explainer.shap_values(X_test_ecom_scaled[:100])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_test_ecom_scaled[:100], feature_names=ecommerce_final_features, show=False)\n",
    "plt.title(f'SHAP Summary Plot - {best_ecom_model_name} (E-commerce)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== FINAL MODEL SELECTION ===\")\n",
    "\n",
    "ecom_best = results_df[results_df['dataset'] == 'E-commerce'].loc[\n",
    "    results_df[results_df['dataset'] == 'E-commerce']['f1_score'].idxmax()\n",
    "]\n",
    "credit_best = results_df[results_df['dataset'] == 'Credit Card'].loc[\n",
    "    results_df[results_df['dataset'] == 'Credit Card']['f1_score'].idxmax()\n",
    "]\n",
    "\n",
    "print(f\"\\nE-commerce Dataset:\")\n",
    "print(f\"Best Model: {ecom_best['model']}\")\n",
    "print(f\"F1 Score: {ecom_best['f1_score']:.4f}\")\n",
    "print(f\"AUC-ROC: {ecom_best['auc_roc']:.4f}\")\n",
    "print(f\"AUC-PR: {ecom_best['auc_pr']:.4f}\")\n",
    "print(f\"Precision: {ecom_best['precision']:.4f}\")\n",
    "print(f\"Recall: {ecom_best['recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nCredit Card Dataset:\")\n",
    "print(f\"Best Model: {credit_best['model']}\")\n",
    "print(f\"F1 Score: {credit_best['f1_score']:.4f}\")\n",
    "print(f\"AUC-ROC: {credit_best['auc_roc']:.4f}\")\n",
    "print(f\"AUC-PR: {credit_best['auc_pr']:.4f}\")\n",
    "print(f\"Precision: {credit_best['precision']:.4f}\")\n",
    "print(f\"Recall: {credit_best['recall']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "joblib.dump(results_df, '../models/model_results.pkl')\n",
    "\n",
    "best_ecom_model = models[ecom_best['model']]\n",
    "best_ecom_model.fit(X_train_ecom_balanced, y_train_ecom_balanced)\n",
    "joblib.dump(best_ecom_model, '../models/best_ecommerce_model.pkl')\n",
    "joblib.dump(scaler_ecom, '../models/ecommerce_scaler.pkl')\n",
    "\n",
    "best_credit_model = models[credit_best['model']]\n",
    "best_credit_model.fit(X_train_credit_balanced, y_train_credit_balanced)\n",
    "joblib.dump(best_credit_model, '../models/best_credit_model.pkl')\n",
    "joblib.dump(scaler_credit, '../models/credit_scaler.pkl')\n",
    "\n",
    "print(\"Models and results saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11. Interim 2 Summary\n",
    "\n",
    "### Key Achievements:\n",
    "1. âœ… Built and trained Logistic Regression, Random Forest, XGBoost, and LightGBM models\n",
    "2. âœ… Applied SMOTE to handle class imbalance\n",
    "3. âœ… Evaluated models with AUC-ROC, AUC-PR, F1, Precision, and Recall\n",
    "4. âœ… Used SHAP for explainability\n",
    "5. âœ… Identified and saved best-performing models\n",
    "\n",
    "### Next Steps:\n",
    "1. ðŸ”„ Write a final report (PDF or markdown)\n",
    "2. ðŸ”„ Build a dashboard or web application\n",
    "3. ðŸ”„ Add real-time prediction capability\n",
    "4. ðŸ”„ Write deployment and usage documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
